{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first of all we do a little of analysis, as we open all the different datasets\n",
    "\n",
    "df_inventory = pd.read_parquet('local_data/inventory.parquet', engine='pyarrow')\n",
    "df_abandoned_carts = pd.read_parquet('local_data/abandoned_carts.parquet', engine='pyarrow')\n",
    "df_orders = pd.read_parquet('local_data/orders.parquet', engine='pyarrow')\n",
    "df_regulars = pd.read_parquet('local_data/regulars.parquet', engine='pyarrow')\n",
    "df_users = pd.read_parquet('local_data/users.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see what products are the most purchased and to see the most abandoned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinar_datasets_totales(): \n",
    "    exploded_items = df_orders['ordered_items'].explode()  \n",
    "    item_counts = exploded_items.value_counts()\n",
    "    item_counts_df_orders = item_counts.reset_index()\n",
    "    item_counts_df_orders.columns = ['product_id', 'number_of_orders']\n",
    "    total_orders = len(df_orders)\n",
    "    item_counts_df_orders['purchase_probability'] = item_counts_df_orders['number_of_orders'] / total_orders\n",
    "    #print(\"primeros cinco df orders: \", item_counts_df_orders.head())\n",
    "\n",
    "    # Paso 2: Crear DataFrame de carritos abandonados\n",
    "    exploded_items_abandoned = df_abandoned_carts['variant_id'].explode()\n",
    "    item_counts_abandoned = exploded_items_abandoned.value_counts()\n",
    "    item_counts_df_abandoned = item_counts_abandoned.reset_index()\n",
    "    item_counts_df_abandoned.columns = ['product_id', 'number_of_abandoned']\n",
    "    total_abandoned_carts = len(df_abandoned_carts)\n",
    "    item_counts_df_abandoned['abandon_probability'] = item_counts_df_abandoned['number_of_abandoned'] / total_abandoned_carts\n",
    "    #print(\"primeros cinco df abandoned: \", item_counts_df_abandoned.head())\n",
    "\n",
    "    # Paso 3: Filtrar para incluir solo productos en inventario\n",
    "    df_orders_inventory = item_counts_df_orders[item_counts_df_orders[\"product_id\"].isin(df_inventory[\"variant_id\"])]\n",
    "    df_abandoned_inventory = item_counts_df_abandoned[item_counts_df_abandoned[\"product_id\"].isin(df_inventory[\"variant_id\"])]\n",
    "\n",
    "    # Paso 4: Combinar los DataFrames\n",
    "    df_combined = df_orders_inventory.merge(df_abandoned_inventory, on=\"product_id\", how=\"outer\")\n",
    "\n",
    "    # Rellenar valores NaN con 0, ya que algunos productos pueden no estar en ambos DataFrames\n",
    "    df_combined.fillna(0, inplace=True)\n",
    "\n",
    "    #print(df_combined.head())\n",
    "    #print(\"Longitud del dataset combinado: \", len(df_combined), \" y longitud del inventario: \", len(df_inventory))\n",
    "    \n",
    "    \n",
    "    # Configuración de la visualización\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Top 10 productos por frecuencia de compra\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x='product_id', y='number_of_orders', data=df_combined.sort_values('number_of_orders', ascending=False).head(10))\n",
    "    plt.title('Top 10 Productos por Frecuencia de Compra')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Top 10 productos por probabilidad de compra\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x='product_id', y='purchase_probability', data=df_combined.sort_values('purchase_probability', ascending=False).head(10))\n",
    "    plt.title('Top 10 Productos por Probabilidad de Compra')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Top 10 productos por frecuencia de abandono\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x='product_id', y='number_of_abandoned', data=df_combined.sort_values('number_of_abandoned', ascending=False).head(10))\n",
    "    plt.title('Top 10 Productos por Frecuencia de Abandono')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Top 10 productos por probabilidad de abandono\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.barplot(x='product_id', y='abandon_probability', data=df_combined.sort_values('abandon_probability', ascending=False).head(10))\n",
    "    plt.title('Top 10 Productos por Probabilidad de Abandono')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of the things we expect at first in our bussiness is that if price is reduced, customers\n",
    "will be more attracted to that product than before and therefor will have a bigger purchased probability.\n",
    "Let's consider a significat discount those bigger than the 20%. If there's a \"significant discount\", then \n",
    "we believe there'll be more purchase probability than if there was less %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_per_discount_check(percentage):\n",
    "    data=df_inventory\n",
    "    menos=[]\n",
    "    mas=[]\n",
    "    for index, row in data.iterrows():\n",
    "        if row['compare_at_price'] == 0:\n",
    "            # Opción 1: Continuar con la siguiente iteración\n",
    "            continue\n",
    "\n",
    "            # Opción 2: Establecer el porcentaje de descuento en cero o algún valor predeterminado\n",
    "            # porcentaje_descuento = 0\n",
    "        else:\n",
    "            descuento = row['compare_at_price'] - row['price']\n",
    "            porcentaje_descuento = (descuento / row['compare_at_price']) * 100\n",
    "\n",
    "            # Comparar el porcentaje de descuento\n",
    "            if porcentaje_descuento > percentage:\n",
    "                mas.append(row['variant_id'])\n",
    "            else:\n",
    "                menos.append(row['variant_id'])\n",
    "    \n",
    "    # Crear subdataframes\n",
    "    df_mas = data[data['variant_id'].isin(mas)]\n",
    "    df_menos = data[data['variant_id'].isin(menos)]\n",
    "    \n",
    "    # Calcular la probabilidad de ser comprado\n",
    "    total_orders = df_orders['ordered_items'].explode().value_counts()\n",
    "    df_mas['purchase_probability'] = df_mas['variant_id'].apply(lambda x: total_orders.get(x, 0) / len(df_orders))\n",
    "    df_menos['purchase_probability'] = df_menos['variant_id'].apply(lambda x: total_orders.get(x, 0) / len(df_orders))\n",
    "    print(df_mas.head(),df_menos.head())\n",
    "    return df_mas, df_menos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    But we can see how this has nothing to do with the disccount we make on the products unless we \n",
    "    have a huge disccount that catches the attention of our client. So maybe we should ask ourselfs that for our\n",
    "    online shop we should focus more on some specific target products. Which ones? let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_pedidos_por_tipo(): #nos da un graph e info sobre los product_type mas demandados\n",
    "    variant_info = df_inventory.set_index('variant_id')[['product_type', 'price']]\n",
    "\n",
    "    # Filtrar variant_id en df_orders y df_abandoned_carts que están en df_inventory\n",
    "    valid_variants = set(df_inventory['variant_id'])\n",
    "    ordered_variants = df_orders['ordered_items'].explode().map(lambda x: x if x in valid_variants else None).dropna()\n",
    "    abandoned_variants = df_abandoned_carts['variant_id'].explode().map(lambda x: x if x in valid_variants else None).dropna()\n",
    "    \n",
    "    # Asignar product_type y price a cada variant_id en los pedidos y en los abandonos\n",
    "    ordered_variants_info = variant_info.loc[ordered_variants]\n",
    "    abandoned_variants_info = variant_info.loc[abandoned_variants]\n",
    "\n",
    "    # Calcular ingresos por variant_id\n",
    "    ordered_variants_info['revenue'] = ordered_variants_info['price']\n",
    "    abandoned_variants_info['lost_revenue'] = abandoned_variants_info['price']\n",
    "\n",
    "    # Agregar y agrupar por product_type\n",
    "    revenue_per_type = ordered_variants_info.groupby('product_type')['revenue'].sum()\n",
    "    lost_revenue_per_type = abandoned_variants_info.groupby('product_type')['lost_revenue'].sum()\n",
    "\n",
    "    # Calcular ingresos netos por product_type\n",
    "    net_revenue_per_type = revenue_per_type - lost_revenue_per_type\n",
    "\n",
    "    # Contar pedidos y abandonos por product_type\n",
    "    order_counts = ordered_variants_info['product_type'].value_counts()\n",
    "    abandoned_counts = abandoned_variants_info['product_type'].value_counts()\n",
    "\n",
    "    # Crear un nuevo DataFrame\n",
    "    top_types = pd.DataFrame({\n",
    "        'order_count': order_counts,\n",
    "        'abandoned_count': abandoned_counts.reindex(order_counts.index, fill_value=0),\n",
    "        'net_revenue': net_revenue_per_type.reindex(order_counts.index, fill_value=0)\n",
    "    }).reset_index().rename(columns={'index': 'product_type'})\n",
    "\n",
    "    # Ordenar por ingresos netos (net_revenue) de mayor a menor\n",
    "    top_types = top_types.sort_values(by='net_revenue', ascending=False)\n",
    "    \n",
    "    top_types = top_types.sort_values(by='net_revenue', ascending=False)\n",
    "    top_10_types = top_types.head(10)\n",
    "    \n",
    "    print(top_10_types)\n",
    "\n",
    "    # Crear un gráfico de barras para el ingreso neto de las 10 principales categorías\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(top_10_types['product_type'], top_10_types['net_revenue'], color='skyblue')\n",
    "    plt.xlabel('Product Type')\n",
    "    plt.ylabel('Net Revenue')\n",
    "    plt.title('Top 10 Product Types by Net Revenue')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    return top_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that clearly long-life-milk-substitudes is the product_type with a highest revenue. \n",
    "This will be very useful since we now can focus more specificaly on this and others really high reveneu product\n",
    "types. I believe that regular users do buy a really high percentage on products belonging to the first \n",
    "five highest revenues ones. Let's check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_users_product_type():\n",
    "    # Mapear variant_id a product_type\n",
    "    variant_info = df_inventory.set_index('variant_id')[['product_type', 'price']].to_dict('index')\n",
    "\n",
    "    # Expandir los items ordenados y abandonados en df_orders y df_abandoned_carts\n",
    "    expanded_orders = df_orders.explode('ordered_items')\n",
    "    expanded_abandoned = df_abandoned_carts.explode('variant_id')\n",
    "\n",
    "    # Filtrar variant_id en df_orders y df_abandoned_carts que están en df_inventory\n",
    "    valid_variants = set(df_inventory['variant_id'])\n",
    "    expanded_orders = expanded_orders[expanded_orders['ordered_items'].isin(valid_variants)]\n",
    "    expanded_abandoned = expanded_abandoned[expanded_abandoned['variant_id'].isin(valid_variants)]\n",
    "\n",
    "    # Asignar product_type y price a cada variant_id en los pedidos y abandonos\n",
    "    expanded_orders['product_type'] = expanded_orders['ordered_items'].map(lambda x: variant_info[x]['product_type'])\n",
    "    expanded_orders['price'] = expanded_orders['ordered_items'].map(lambda x: variant_info[x]['price'])\n",
    "    expanded_abandoned['product_type'] = expanded_abandoned['variant_id'].map(lambda x: variant_info[x]['product_type'])\n",
    "\n",
    "    # Función para manejar grupos vacíos al encontrar el product_type más común\n",
    "    def most_common_product_type(x):\n",
    "        if len(x) > 0:\n",
    "            return x.value_counts().idxmax()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Contar pedidos, abandonos y encontrar product_type más común por user_id\n",
    "    user_order_counts = expanded_orders['user_id'].value_counts()\n",
    "    user_abandoned_counts = expanded_abandoned['user_id'].value_counts()\n",
    "    most_bought_product_type = expanded_orders.groupby('user_id')['product_type'].agg(most_common_product_type)\n",
    "    most_abandoned_product_type = expanded_abandoned.groupby('user_id')['product_type'].agg(most_common_product_type)\n",
    "\n",
    "    # Calcular el revenue por usuario\n",
    "    revenue_per_user = expanded_orders.groupby('user_id')['price'].sum()\n",
    "\n",
    "   # Crear un nuevo DataFrame\n",
    "    best_users = pd.DataFrame({\n",
    "        'user_id': user_order_counts.index,\n",
    "        'order_count': user_order_counts,\n",
    "        'most_bought_product_type': most_bought_product_type,\n",
    "        'abandoned_count': user_abandoned_counts.reindex(user_order_counts.index, fill_value=0),\n",
    "        'most_abandoned_product_type': most_abandoned_product_type.reindex(user_order_counts.index),\n",
    "        'revenue': revenue_per_user\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "    # Ordenar el DataFrame por 'revenue' en orden descendente\n",
    "    best_users = best_users.sort_values(by='revenue', ascending=False)\n",
    "\n",
    "    print(best_users.head())\n",
    "    return best_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, now we have a dataset with every user with information according their revenue, their total orders, their total\n",
    "abandons, their fav product type..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_combinar_datasets_totales():\n",
    "    # Aquí, suponemos que los DataFrames ya están cargados o los cargamos dentro de esta función.\n",
    "    # También, asegúrate de que la función 'combinar_datasets_totales' devuelva 'df_combined'.\n",
    "\n",
    "    df_combined = combinar_datasets_totales()\n",
    "\n",
    "    # Verificar que el resultado es un DataFrame.\n",
    "    assert isinstance(df_combined, pd.DataFrame), \"El resultado debe ser un DataFrame.\"\n",
    "\n",
    "    # Comprobar que las columnas esperadas están presentes.\n",
    "    expected_columns = ['product_id', 'number_of_orders', 'purchase_probability', 'number_of_abandoned', 'abandon_probability']\n",
    "    for column in expected_columns:\n",
    "        assert column in df_combined.columns, f\"Falta la columna esperada: {column}\"\n",
    "\n",
    "    # Verificar que no hay valores NaN inesperados.\n",
    "    assert df_combined.notna().all().all(), \"No deben existir valores NaN inesperados.\"\n",
    "\n",
    "    # Opcional: Comprobar el tamaño del DataFrame resultante.\n",
    "    # assert len(df_combined) > 0, \"El DataFrame combinado no debe estar vacío.\"\n",
    "\n",
    "    print(\"Todas las pruebas pasaron correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_users_product_type():\n",
    "    # Crear datos de prueba\n",
    "    mock_inventory_data = {\n",
    "        'variant_id': [1, 2],\n",
    "        'product_type': ['type1', 'type2'],\n",
    "        'price': [10.0, 20.0]\n",
    "    }\n",
    "    mock_orders_data = {\n",
    "        'user_id': ['user1', 'user2', 'user1'],\n",
    "        'ordered_items': [[1], [2], [1]]\n",
    "    }\n",
    "    mock_abandoned_carts_data = {\n",
    "        'user_id': ['user1', 'user2'],\n",
    "        'variant_id': [1, 2]\n",
    "    }\n",
    "\n",
    "    df_inventory = pd.DataFrame(mock_inventory_data)\n",
    "    df_orders = pd.DataFrame(mock_orders_data)\n",
    "    df_abandoned_carts = pd.DataFrame(mock_abandoned_carts_data)\n",
    "\n",
    "    # Ejecutar la función best_users_product_type\n",
    "    best_users = best_users_product_type()\n",
    "    \n",
    "\n",
    "    # Comprobaciones de la prueba\n",
    "    assert isinstance(best_users, pd.DataFrame), \"El resultado debe ser un DataFrame.\"\n",
    "    expected_columns = ['user_id', 'order_count', 'most_bought_product_type', 'abandoned_count', 'most_abandoned_product_type', 'revenue']\n",
    "    for column in expected_columns:\n",
    "        assert column in best_users.columns, f\"Falta la columna esperada: {column}\"\n",
    " \n",
    "    \n",
    "    print(\"Todas las pruebas pasaron correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_contar_pedidos_por_tipo():\n",
    "    # Crear datos de prueba\n",
    "    mock_inventory_data = {\n",
    "        'variant_id': [1, 2, 3],\n",
    "        'product_type': ['type1', 'type2', 'type3'],\n",
    "        'price': [10.0, 20.0, 15.0]\n",
    "    }\n",
    "    mock_orders_data = {\n",
    "        'user_id': ['user1', 'user2', 'user1'],\n",
    "        'ordered_items': [[1, 2], [2], [3]]\n",
    "    }\n",
    "    mock_abandoned_carts_data = {\n",
    "        'user_id': ['user1', 'user2'],\n",
    "        'variant_id': [3, 1]\n",
    "    }\n",
    "\n",
    "    df_inventory = pd.DataFrame(mock_inventory_data)\n",
    "    df_orders = pd.DataFrame(mock_orders_data)\n",
    "    df_abandoned_carts = pd.DataFrame(mock_abandoned_carts_data)\n",
    "\n",
    "    # Ejecutar la función contar_pedidos_por_tipo\n",
    "    top_types = contar_pedidos_por_tipo()\n",
    "\n",
    "    # Comprobaciones de la prueba\n",
    "    assert isinstance(top_types, pd.DataFrame), \"El resultado debe ser un DataFrame.\"\n",
    "    expected_columns = ['product_type', 'order_count', 'abandoned_count', 'net_revenue']\n",
    "    for column in expected_columns:\n",
    "        assert column in top_types.columns, f\"Falta la columna esperada: {column}\"\n",
    "    assert all(column in top_types.columns for column in expected_columns), \"El DataFrame no tiene las columnas esperadas.\"\n",
    "    \n",
    "    print(\"Todas las pruebas pasaron correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, let's check what would be the bestest vendors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vendors_with_biggest_revenue():\n",
    "    # Mapear variant_id a vendor y price\n",
    "    variant_info = df_inventory.set_index('variant_id')[['vendor', 'price']].to_dict('index')\n",
    "\n",
    "    # Expandir los items ordenados en df_orders\n",
    "    expanded_orders = df_orders.explode('ordered_items')\n",
    "\n",
    "    # Asignar vendor y price a cada variant_id en los pedidos\n",
    "    expanded_orders['vendor'] = expanded_orders['ordered_items'].map(lambda x: variant_info[x]['vendor'])\n",
    "    expanded_orders['revenue'] = expanded_orders['ordered_items'].map(lambda x: variant_info[x]['price'])\n",
    "\n",
    "    # Calcular el ingreso total por vendor\n",
    "    total_revenue_per_vendor = expanded_orders.groupby('vendor')['revenue'].sum()\n",
    "\n",
    "    # Crear un nuevo DataFrame ordenado ascendentemente por ingresos\n",
    "    top_vendors = total_revenue_per_vendor.sort_values(ascending=True).reset_index()\n",
    "\n",
    "    # Crear un gráfico de barras\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top_vendors['vendor'], top_vendors['revenue'], color='skyblue')\n",
    "    plt.xlabel('Total Revenue')\n",
    "    plt.ylabel('Vendor')\n",
    "    plt.title('Vendors with Biggest Revenue')\n",
    "    plt.show()\n",
    "\n",
    "    print(top_vendors.head())\n",
    "    return top_vendors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zrive-ds-Ll_yjRU7-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
